{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge\n",
    "In this module, we learned how to approach and solve regression problems using linear regression models. Throughout the module, you worked on a house price dataset from Kaggle. In this challenge, you will keep working on this dataset.\n",
    "\n",
    "The scenario\n",
    "The housing market is one of the most crucial parts of the economy for every country. Purchasing a home is one of the primary ways to build wealth and savings for people. In this respect, predicting prices in the housing market is a very central topic in economic and financial circles.\n",
    "\n",
    "The house price dataset from Kaggle includes several features of the houses along with their sale prices at the time they are sold. So far, in this module, you built and implemented some models using this dataset.\n",
    "\n",
    "In this challenge, you are required to improve your model with respect to its prediction performance.\n",
    "\n",
    "To complete this challenge, submit a Jupyter notebook containing your solutions to the following tasks.\n",
    "\n",
    "Steps\n",
    "Load the houseprices data from Thinkful's database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy import create_engine\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mssubclass</th>\n",
       "      <th>mszoning</th>\n",
       "      <th>lotfrontage</th>\n",
       "      <th>lotarea</th>\n",
       "      <th>street</th>\n",
       "      <th>alley</th>\n",
       "      <th>lotshape</th>\n",
       "      <th>landcontour</th>\n",
       "      <th>utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>poolarea</th>\n",
       "      <th>poolqc</th>\n",
       "      <th>fence</th>\n",
       "      <th>miscfeature</th>\n",
       "      <th>miscval</th>\n",
       "      <th>mosold</th>\n",
       "      <th>yrsold</th>\n",
       "      <th>saletype</th>\n",
       "      <th>salecondition</th>\n",
       "      <th>saleprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  mssubclass mszoning  lotfrontage  lotarea street alley lotshape  \\\n",
       "0   1          60       RL         65.0     8450   Pave  None      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave  None      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave  None      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave  None      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave  None      IR1   \n",
       "\n",
       "  landcontour utilities  ... poolarea poolqc fence miscfeature miscval mosold  \\\n",
       "0         Lvl    AllPub  ...        0   None  None        None       0      2   \n",
       "1         Lvl    AllPub  ...        0   None  None        None       0      5   \n",
       "2         Lvl    AllPub  ...        0   None  None        None       0      9   \n",
       "3         Lvl    AllPub  ...        0   None  None        None       0      2   \n",
       "4         Lvl    AllPub  ...        0   None  None        None       0     12   \n",
       "\n",
       "  yrsold  saletype  salecondition  saleprice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "df1 = pd.read_sql_query('select* from houseprices', con = engine)\n",
    "\n",
    "engine.dispose()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do data cleaning, exploratory data analysis, and feature engineering. You can use your previous work in this module. But make sure that your work is satisfactory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   overallcond  1460 non-null   int64\n",
      " 1   grlivarea    1460 non-null   int64\n",
      " 2   fullbath     1460 non-null   int64\n",
      " 3   garagecars   1460 non-null   int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 45.8 KB\n"
     ]
    }
   ],
   "source": [
    "X = pd.concat([df1[['overallcond','grlivarea','fullbath','garagecars']]], axis = 1)\n",
    "y = df1['saleprice']\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, split your data into train and test sets where 20% of the data resides in the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 4)\n",
      "(1095,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=40)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 5)\n",
      "(1095,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>saleprice</td>    <th>  R-squared:         </th> <td>   0.627</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.626</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   458.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 28 May 2020</td> <th>  Prob (F-statistic):</th> <td>1.02e-231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:32:16</td>     <th>  Log-Likelihood:    </th> <td> -13394.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1095</td>      <th>  AIC:               </th> <td>2.680e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1090</td>      <th>  BIC:               </th> <td>2.682e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td>-4.784e+04</td> <td> 1.02e+04</td> <td>   -4.687</td> <td> 0.000</td> <td>-6.79e+04</td> <td>-2.78e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overallcond</th> <td> 4494.2364</td> <td> 1405.675</td> <td>    3.197</td> <td> 0.001</td> <td> 1736.101</td> <td> 7252.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grlivarea</th>   <td>   73.5275</td> <td>    3.800</td> <td>   19.352</td> <td> 0.000</td> <td>   66.072</td> <td>   80.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fullbath</th>    <td> 1.444e+04</td> <td> 3675.983</td> <td>    3.929</td> <td> 0.000</td> <td> 7229.801</td> <td> 2.17e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garagecars</th>  <td> 3.974e+04</td> <td> 2362.069</td> <td>   16.824</td> <td> 0.000</td> <td> 3.51e+04</td> <td> 4.44e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>208.905</td> <th>  Durbin-Watson:     </th> <td>   1.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2553.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.489</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.416</td>  <th>  Cond. No.          </th> <td>1.10e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.1e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              saleprice   R-squared:                       0.627\n",
       "Model:                            OLS   Adj. R-squared:                  0.626\n",
       "Method:                 Least Squares   F-statistic:                     458.4\n",
       "Date:                Thu, 28 May 2020   Prob (F-statistic):          1.02e-231\n",
       "Time:                        00:32:16   Log-Likelihood:                -13394.\n",
       "No. Observations:                1095   AIC:                         2.680e+04\n",
       "Df Residuals:                    1090   BIC:                         2.682e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const       -4.784e+04   1.02e+04     -4.687      0.000   -6.79e+04   -2.78e+04\n",
       "overallcond  4494.2364   1405.675      3.197      0.001    1736.101    7252.372\n",
       "grlivarea      73.5275      3.800     19.352      0.000      66.072      80.983\n",
       "fullbath     1.444e+04   3675.983      3.929      0.000    7229.801    2.17e+04\n",
       "garagecars   3.974e+04   2362.069     16.824      0.000    3.51e+04    4.44e+04\n",
       "==============================================================================\n",
       "Omnibus:                      208.905   Durbin-Watson:                   1.896\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2553.070\n",
       "Skew:                           0.489   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.416   Cond. No.                     1.10e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.1e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "results = sm.OLS(y_train, X_train).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const          46.029260\n",
       "overallcond     1.068257\n",
       "grlivarea       1.814034\n",
       "fullbath        1.839777\n",
       "garagecars      1.401560\n",
       "dtype: float64"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "pd.Series([variance_inflation_factor(X_train.values, i)\n",
    "   for i in range(X_train.shape[1])], index = X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build several linear regression models including Lasso, Ridge, or ElasticNet and train them in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model on the training set is: 0.6271706833654755\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: 0.6398552847776747\n",
      "Mean absolute error of the prediction is: 29981.144121433623\n",
      "Mean squared error of the prediction is: 1937784252.938219\n",
      "Root mean squared error of the prediction is: 44020.27093213102\n",
      "Mean absolute percentage error of the prediction is: 18.19697706404159\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lrm = LinearRegression()\n",
    "lrm.fit(X_train, y_train)\n",
    "y_lrmpredict = lrm.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"R-squared of the model on the training set is: {}\".format(lrm.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the test set is: {}\".format(lrm.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_lrmpredict)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_lrmpredict)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_lrmpredict)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_lrmpredict) / y_test)) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use k-fold cross-validation to select the best hyperparameters if your models include one!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda = 1.0\n",
      "Best R-squared of the model for Ridge on the training set is: 0.6271701447633151\n",
      "-----Test set statistics-----\n",
      "R-squared of the Ridge model on the test set is: 0.6398299361146639\n",
      "Mean absolute error of the Ridge prediction is: 29975.193289471514\n",
      "Mean squared error of the Ridge prediction is: 1937920643.222289\n",
      "Root mean squared error of the Ridge prediction is: 44021.82008075415\n",
      "Mean absolute percentage error of the Ridge prediction is: 18.19032384380772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "RG = Ridge()\n",
    "pms = [{'alpha':[np.power(10.0,p) for p in np.arange(0,40,1)]}]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "RGcv = GridSearchCV(RG, param_grid=pms)\n",
    "\n",
    "RGcv.fit(X_train, y_train)\n",
    "\n",
    "print('Best lambda = ' + str(RGcv.best_estimator_.alpha))\n",
    "y_test_predRG = RGcv.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "\n",
    "RGbest = Ridge(alpha =1)\n",
    "RGbest.fit(X_train, y_train)\n",
    "\n",
    "y_test_predRG = RGbest.predict(X_test)\n",
    "\n",
    "print(\"Best R-squared of the model for Ridge on the training set is: {}\".format(RGcv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the Ridge model on the test set is: {}\".format(RGcv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the Ridge prediction is: {}\".format(mean_absolute_error(y_test, y_test_predRG)))\n",
    "print(\"Mean squared error of the Ridge prediction is: {}\".format(mse(y_test, y_test_predRG)))\n",
    "print(\"Root mean squared error of the Ridge prediction is: {}\".format(rmse(y_test, y_test_predRG)))\n",
    "print(\"Mean absolute percentage error of the Ridge prediction is: {}\".format(np.mean(np.abs((y_test - y_test_predRG) / y_test)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 1.0\n",
      "R-squared of the Lasso model in training set is: 0.6271706820511271\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.6398574577058384\n",
      "Mean absolute error of the prediction is: 29980.874342549745\n",
      "Mean squared error of the prediction is: 1937772561.3437011\n",
      "Root mean squared error of the prediction is: 44020.13813408247\n",
      "Mean absolute percentage error of the prediction is: 18.19678369229411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import  LassoCV, RidgeCV, ElasticNetCV\n",
    "alphas = [np.power(10.0,p) for p in np.arange(0,40,1)]\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=5)\n",
    "\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = lasso_cv.predict(X_train)\n",
    "y_preds_test = lasso_cv.predict(X_test)\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(lasso_cv.alpha_))\n",
    "print(\"R-squared of the Lasso model in training set is: {}\".format(lasso_cv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(lasso_cv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 0.001\n",
      "R-squared of the Elastic model in training set is: 0.6271705215730331\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.6398415728082749\n",
      "Mean absolute error of the prediction is: 29977.882775522594\n",
      "Mean squared error of the prediction is: 1937858031.1647394\n",
      "Root mean squared error of the prediction is: 44021.10892702204\n",
      "Mean absolute percentage error of the prediction is: 18.193331209500396\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alphas = [np.power(10.0,p) for p in np.arange(-3,40,1)]\n",
    "EL_cv = ElasticNetCV(alphas=alphas, cv=10, max_iter=100000)\n",
    "\n",
    "EL_cv.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = EL_cv.predict(X_train)\n",
    "y_preds_test = EL_cv.predict(X_test)\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(EL_cv.alpha_))\n",
    "print(\"R-squared of the Elastic model in training set is: {}\".format(EL_cv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(EL_cv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your best model on the test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is linear regression with an lambda of 0.01. This produces the least % error between train and test set (18.19%) paired with similar closeness in r-squared values to the training set (~0.63 and ~0.64 respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, you have only used the features in the dataset. However, house prices can be affected by many factors like economic activity and the interest rates at the time they are sold. So, try to find some useful factors that are not included in the dataset. Integrate these factors into your model and assess the prediction performance of your model. Discuss the implications of adding these external variables into your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mosold</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January</td>\n",
       "      <td>5.71</td>\n",
       "      <td>5.97</td>\n",
       "      <td>5.29</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February</td>\n",
       "      <td>5.86</td>\n",
       "      <td>6.02</td>\n",
       "      <td>5.44</td>\n",
       "      <td>4.77</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>March</td>\n",
       "      <td>5.97</td>\n",
       "      <td>5.88</td>\n",
       "      <td>5.42</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>April</td>\n",
       "      <td>6.16</td>\n",
       "      <td>5.88</td>\n",
       "      <td>5.47</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May</td>\n",
       "      <td>6.21</td>\n",
       "      <td>5.97</td>\n",
       "      <td>5.60</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.28</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mosold  2006  2007  2008  2009  2010  2011\n",
       "0   January  5.71  5.97  5.29  4.72  4.44   4.1\n",
       "1  February  5.86  6.02  5.44  4.77  4.37   4.2\n",
       "2     March  5.97  5.88  5.42  4.64  4.33   4.1\n",
       "3     April  6.16  5.88  5.47  4.50  4.42   4.1\n",
       "4       May  6.21  5.97  5.60  4.52  4.28   3.8"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing a table with year and month 15yr mortage interest rate data to be matched with houseprice data\n",
    "intrates = pd.read_csv('https://raw.githubusercontent.com/robholmstrom/Sams_github/master/15yrmortrates.csv')\n",
    "intrates.rename(columns={\"Unnamed: 0\": 'mosold'},inplace=True)\n",
    "intrates.head() # Need to melt columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Melted interest rate dataframe to incorporate month and year 15yr interest rates to match with salesprice of homes\n",
    "intratemelt = pd.melt(intrates, id_vars=['mosold'], value_vars=intrates.columns[1:].tolist(), var_name='yrsold', value_name='15yr_rate')\n",
    "#Changes month column in a interest rate dataframe to sync with df1 (month number in df1)\n",
    "d = {'January':1,\n",
    " 'February':2,\n",
    " 'March':3,\n",
    " 'April':4,\n",
    " 'May':5,\n",
    " 'June':6,\n",
    " 'July':7,\n",
    " 'August':8,\n",
    " 'September':9,\n",
    " 'October':10,\n",
    " 'November':11,\n",
    " 'December':12}\n",
    "\n",
    "intratemelt.mosold = intratemelt.mosold.replace(d)\n",
    "intratemelt.yrsold = pd.to_numeric(intratemelt.yrsold) # is integer in df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge interest rate (mo and yr) to houseprice data on month and year sold\n",
    "dfint = pd.merge(df1,intratemelt, on = ['yrsold', 'mosold'])\n",
    "dfint.sort_values('id',ascending=True, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the feature and label data, but with 15 yr mortgage rates as feature\n",
    "X2 = pd.concat([dfint[['overallcond', 'grlivarea','fullbath','garagecars','15yr_rate']]], axis = 1)\n",
    "y2 = dfint['saleprice']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat tasks as above for OLS to get a sense of F-score and p-values\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, random_state=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 6)\n",
      "(1095,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>saleprice</td>    <th>  R-squared:         </th> <td>   0.628</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.627</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   368.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 28 May 2020</td> <th>  Prob (F-statistic):</th> <td>5.02e-231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:34:53</td>     <th>  Log-Likelihood:    </th> <td> -13403.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1095</td>      <th>  AIC:               </th> <td>2.682e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1089</td>      <th>  BIC:               </th> <td>2.685e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td>-5.495e+04</td> <td> 1.46e+04</td> <td>   -3.755</td> <td> 0.000</td> <td>-8.37e+04</td> <td>-2.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overallcond</th> <td> 4853.1823</td> <td> 1420.746</td> <td>    3.416</td> <td> 0.001</td> <td> 2065.474</td> <td> 7640.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grlivarea</th>   <td>   73.1259</td> <td>    3.813</td> <td>   19.180</td> <td> 0.000</td> <td>   65.645</td> <td>   80.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fullbath</th>    <td> 1.461e+04</td> <td> 3724.334</td> <td>    3.923</td> <td> 0.000</td> <td> 7302.316</td> <td> 2.19e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garagecars</th>  <td>  4.13e+04</td> <td> 2396.826</td> <td>   17.232</td> <td> 0.000</td> <td> 3.66e+04</td> <td>  4.6e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15yr_rate</th>   <td>  676.1384</td> <td> 1985.144</td> <td>    0.341</td> <td> 0.733</td> <td>-3219.001</td> <td> 4571.278</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>203.018</td> <th>  Durbin-Watson:     </th> <td>   1.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2314.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.486</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.056</td>  <th>  Cond. No.          </th> <td>1.56e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.56e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              saleprice   R-squared:                       0.628\n",
       "Model:                            OLS   Adj. R-squared:                  0.627\n",
       "Method:                 Least Squares   F-statistic:                     368.0\n",
       "Date:                Thu, 28 May 2020   Prob (F-statistic):          5.02e-231\n",
       "Time:                        00:34:53   Log-Likelihood:                -13403.\n",
       "No. Observations:                1095   AIC:                         2.682e+04\n",
       "Df Residuals:                    1089   BIC:                         2.685e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const       -5.495e+04   1.46e+04     -3.755      0.000   -8.37e+04   -2.62e+04\n",
       "overallcond  4853.1823   1420.746      3.416      0.001    2065.474    7640.891\n",
       "grlivarea      73.1259      3.813     19.180      0.000      65.645      80.607\n",
       "fullbath     1.461e+04   3724.334      3.923      0.000    7302.316    2.19e+04\n",
       "garagecars    4.13e+04   2396.826     17.232      0.000    3.66e+04     4.6e+04\n",
       "15yr_rate     676.1384   1985.144      0.341      0.733   -3219.001    4571.278\n",
       "==============================================================================\n",
       "Omnibus:                      203.018   Durbin-Watson:                   1.947\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2314.345\n",
       "Skew:                           0.486   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.056   Cond. No.                     1.56e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.56e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X2_train = sm.add_constant(X2_train)\n",
    "X2_test = sm.add_constant(X2_test)\n",
    "print(X2_train.shape)\n",
    "print(y2_train.shape)\n",
    "results = sm.OLS(y2_train, X2_train).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const          92.913512\n",
       "overallcond     1.073863\n",
       "grlivarea       1.796610\n",
       "fullbath        1.824748\n",
       "garagecars      1.410146\n",
       "15yr_rate       1.004704\n",
       "dtype: float64"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate VIF for new feature\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "pd.Series([variance_inflation_factor(X2_train.values, i)\n",
    "   for i in range(X2_train.shape[1])], index = X2_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6257.049245521439"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAD4CAYAAADGmmByAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO29eZxU1Z3w/T1V1VVdvUA3TTcijQGVoB3FQCOyzOu4JAYTJsSIiVEWV8BlzGRRzDPh0RniOyo6RscFNCriTkBfeUgMGhIn87ohSETFICgaWhGapht7qe7qqnueP+reSy23qqu7lt5+38+nP1116i6/e+vW+Z3z247SWiMIgiAIPcXV2wIIgiAI/RtRJIIgCEJGiCIRBEEQMkIUiSAIgpARokgEQRCEjPD0tgD5Zvjw4XrMmDG9LYYgCEK/YuvWrQe11pVOnw06RTJmzBi2bNnS22IIgiD0K5RSnyb7TExbgiAIQkaIIhEEQRAyQhSJIAiCkBGiSARBEISMEEUiCIIgZMSgi9oSBKH3MAxNQ2uQYCiM1+OmotiLy6V6WywhQ0SRCIKQFwxDs3N/M1eu3kJdY4Dqcj8PzZ/M+BGlokz6OWLaEgQhLzS0Bm0lAlDXGODK1VtoaA32smRCpogiEQQhLwRDYVuJWNQ1BgiGwr0kkZAtRJEIgpAXvB431eX+mLbqcj9ej7uXJBKyhSgSQRDyQkWxl4fmT7aVieUjqSj29rJkQqZk7GxXShUCfwF85vHWaq1vUkqNBZ4BhgFvA/O01kGllA9YDdQCDcAPtdafmMf6BXA5EAau01pvNNtnAncDbuA3WutbzXbHc2R6TYIgZB+XSzF+RCnPXz1DorYGGNmYkXQAZ2mtTwG+DsxUSk0FbgPu0lqPAxqJKAjM/41a6+OBu8ztUErVABcCXwNmAvcrpdxKKTdwH3AuUAP8yNyWFOcQBKEP4nIpKkt9jCovorLUJ0pkgJCxItERWsy3BeafBs4C1prtjwHfM1/PNt9jfn62UkqZ7c9orTu01nuA3cAU82+31vpjc7bxDDDb3CfZOQRBEIQ8kRUfiTlz+CtwAHgZ+Aho0lqHzE3qgFHm61HAXgDz88NARXR73D7J2itSnCNevoVKqS1KqS319fWZXKogCIIQR1YUidY6rLX+OlBNZAZxotNm5n+nuazOYruTfA9qrSdrrSdXVjquyyIIgiD0kKxGbWmtm4BXgKlAmVLKcuZXA5+br+uA0QDm50OBQ9Htcfskaz+Y4hyCIAhCnshYkSilKpVSZeZrP/AN4APgz8Acc7MFwAvm6/Xme8zP/6S11mb7hUopnxmNNQ7YDLwFjFNKjVVKeYk45Neb+yQ7hyAIgpAnslFrayTwmBld5QLWaK03KKV2AM8opX4FbAMeNrd/GHhcKbWbyEzkQgCt9ftKqTXADiAEXKO1DgMopa4FNhIJ/31Ea/2+eawlSc4hCIIg5AkVGdgPHiZPnqxlzXZBEITuoZTaqrWe7PSZZLYLgiAIGSGKRBAEQcgIUSSCIAhCRogiEQRBEDJCFIkgCIKQEaJIBEEQhIwQRSIIgiBkhCgSQRAEISNEkQiCIAgZIYpEEARByAhRJIIgCEJGiCIRBEEQMkIUiSAIgpARokgEQRCEjBBFIgiCIGSEKBJBEAQhI0SRCIIgCBkhikQQBEHICFEkgiAIQkaIIhEEQRAyQhSJIAiCkBGiSARBEISMEEUiCIIgZIQoEkEQBCEjRJEIgiAIGSGKRBAEQcgIUSSCIAhCRogiEQRBEDJCFIkgCIKQEaJIBEEQhIwQRSIIgiBkhCgSQRAEISNEkQiCIAgZIYpEEARByAhRJIIgCEJGiCIRBEEQMiJjRaKUGq2U+rNS6gOl1PtKqR+b7cOUUi8rpXaZ/8vNdqWUukcptVsptV0pNSnqWAvM7XcppRZEtdcqpd4197lHKaVSnUMQBEHIH9mYkYSAn2mtTwSmAtcopWqAG4FNWutxwCbzPcC5wDjzbyHwAESUAnATcBowBbgpSjE8YG5r7TfTbE92DkEQBCFPZKxItNb7tNZvm6+bgQ+AUcBs4DFzs8eA75mvZwOrdYQ3gDKl1EjgW8DLWutDWutG4GVgpvnZEK3161prDayOO5bTOQRBEIQ8kVUfiVJqDDAReBMYobXeBxFlA1SZm40C9kbtVme2pWqvc2gnxTkEQRCEPJE1RaKUKgHWAf+itf4y1aYObboH7d2RbaFSaotSakt9fX13dhUEQRC6ICuKRClVQESJPKm1fs5s3m+apTD/HzDb64DRUbtXA5930V7t0J7qHDForR/UWk/WWk+urKzs2UUKgiAIjmQjaksBDwMfaK3/M+qj9YAVebUAeCGqfb4ZvTUVOGyapTYC5yilyk0n+znARvOzZqXUVPNc8+OO5XQOQRAEIU94snCMGcA84F2l1F/Ntv8F3AqsUUpdDvwduMD87PfAt4HdQBtwKYDW+pBSahnwlrndv2utD5mvrwJWAX7gRfOPFOcQhLxjGJqG1iDBUBivx01FsReXy8kyKwgDCxUJhBo8TJ48WW/ZsqW3xRAGGIah2bm/mStXb6GuMUB1uZ+H5k9m/IhSUSbCgEAptVVrPdnpM8lsF4Qs0NAatJUIQF1jgCtXb6GhNdjLkglC7hFFIghZIBgK20rEoq4xQDAU7iWJBCF/iCIRhCzg9bipLvfHtFWX+/F63L0kkSDkD1EkgpAFKoq9PDR/sq1MLB9JRbG3lyUThNyTjagtQRj0uFyK8SNKef7qGRK1JQw6RJEIQpZwuRSVpb7eFkMQ8o6YtgRBEISMEEUiCIIgZIQoEkEQBCEjRJEIgiAIGSGKRBAEQcgIUSSCIAhCRogiEQRBEDJCFIkgCIKQEaJIBEEQhIwQRSIIgiBkhCgSQRAEISNEkQiCIAgZIYpEEARByAhRJIIgCEJGiCIRBEEQMkIUiSAIgpARokgEQRCEjBBFIgiCIGSELLUrCIKNYWgaWoOy7rzQLUSRCIIARJTIzv3NXLl6C3WNAarL/Tw0fzLjR5SKMhFSIqYtQRAAaGgN2koEoK4xwJWrt9DQGuxlyYS+jigSQRAACIbCthKxqGsMEAyFe0kiob8gikQQBAC8HjfV5f6YtupyP16Pu5ckEvoLokgEYYBjGJr65g4+a2zjUGsHB5rb+ayxjfrmDgxD29tVFHt5aP5kW5lYPpKKYm9viS70E8TZLggDmGgHemWJjxtmjuf6tdsdnekul2L8iFKev3qGRG1lwGCMfJMZiSAMYKId6IvPOM5WIuDsTHe5FJWlPkaVF1FZ6hvwHWC2sRT3efe/yozb/sx597/Kzv3NMTO/gYgoEkEYwEQ70Mv8BeJMzzGDNfJNFIkgDGCiHehNgU5xpueYwRr5JopEEAYw0Q70Fa98xPI5E8SZnkMGa+Sb0npg2+7imTx5st6yZUtviyEIeSPa+ev3ugkZms6QMWgcwflkIFcHUEpt1VpPdvpMorYEYYBjOdCF3DNYI9+yYtpSSj2ilDqglHovqm2YUuplpdQu83+52a6UUvcopXYrpbYrpSZF7bPA3H6XUmpBVHutUupdc597lFIq1TkEQRB6i8EY+ZYtH8kqYGZc243AJq31OGCT+R7gXGCc+bcQeAAiSgG4CTgNmALcFKUYHjC3tfab2cU5BEEQhDyRFUWitf4LcCiueTbwmPn6MeB7Ue2rdYQ3gDKl1EjgW8DLWutDWutG4GVgpvnZEK316zri0FkddyyncwiCkCWiM+Pjs+EFAXLrIxmhtd4HoLXep5SqMttHAXujtqsz21K11zm0pzpHDEqphURmNBxzzDGZXJMwgBiMGcjdZSA7j4Xs0Rvhv05Pn+5Be9porR/UWk/WWk+urKzszq7CAGWwZiB3l8GaYCd0j1wqkv2mWQrz/wGzvQ4YHbVdNfB5F+3VDu2pziEIKU0y0kGmx2BNsBO6Ry4VyXrAirxaALwQ1T7fjN6aChw2zVMbgXOUUuWmk/0cYKP5WbNSaqoZrTU/7lhO5xAGOV3NOKSDTI/BmmAndI9shf8+DbwOjFdK1SmlLgduBb6plNoFfNN8D/B74GNgN/AQcDWA1voQsAx4y/z7d7MN4CrgN+Y+HwEvmu3JziEMcrqaceSigxyITmkpLS+kg2S2CwOSzxrbmHHbnxPaX11yJqPKi7LuRB7ITmkJShBAMtuFQYg144g2X0XPOLKdgZxsBvT81TP6fVa5ZMYLXSFFG4UBSTommZ5mIDuZsMTnIgxmZEYiDEhyVfMomQlrxBBfyhmQIAxkZEYiDFhyUfMomQkrZGhxSguDFpmRCEI3cDJhVZb46AwZFPvcPLNwKgUuRYHHRZk/P05pcYYLvY0oEkHoBvFO/Imjy7hh5nh++OAbtqlr+ZwJjBhSSJk/97ORgRwtJvQfxLQlCN0g3ol/3dnjuH7t9hhT1/Vrt/NpQ1tesuQlQ1/oC8iMRBDSxDIhlRZ6eHbhVJSCzrB2jNYq8rrzErEl0WJCX0AUiTAo6a5fwcmEdNv5E3C7lGO0VlswnJeIra7yZfKN+GsGJ2LaEgYdPan862RCWrJuO1prls+ZEBOttXzOBL5SUZRRxFa65Vb6UgmT3qioPBDL0vRHZEbSS8jIrWtydY96koWezITkUopbX/wbzy6cSliDW0Gxz00wrNl3ONAjubvjQO9La4TnO7tfAg36DqJIegH5AXRNLu9RT/wKyUxITYFO6ls68HrcVJb6siJ3dzvk7pQwyeUAJt/+moFclqa/IaatXkAibboml/eoJ5V/nUxIt50/gXVb98aYkrIhd6465FybnvJdcl4CDfoOokh6gd7+AfQHu3Iu71FP/ArRJqRXl5zJmkXTOL6ymFvOmxAz28iG3LnqkHM9gMm3v0bWSuk7iGmrF+jNSJv+YlbL5T3qqV8hHRNStNwTR5ex+IzjqCj2opTCMHRa99jqkOO/o0w75FwPYPLtr8nVfRK6j6xHkmcMQ3OwtYO2jjB7DrZyz6Zd1Ld0pN2ZZ2rjrm/u4Lz7X03ooPuaXbm/KLx4LLnvenknC6aPZcm67T2Sv6vvuSfPQX/57ruDBK3kj1TrkYgiySNOnePKubWMLCtMqy5TNjrXrhZ86kv0107CMDRffNnOD1a+npNOu6fPQX9VzkLfIJUiER9JFunK9+Bko170xFbCBmn9kLNh4+5PduVcVO/NBy6XQmvnjPdsmJF6+hzE+3mev3qGKBEhK4giyRLpRMRkaqPOho27LyWwDWRyqbAzeQ76q3IW+jaiSLJEOqPETDuXbHROMirND7lU2P1pVikMDkSRZIl0RomZdi7Z6pyyNSrtD2HEvUUuFXZXz0F/+176m7xCIhL+myXSCVfNNDwy1+GV3XFuOwYOzKtleLEXl8vVK47xfDrn0zlXdzLOu3ueZM9Bf3Oo9zd5BWckaitL9NYPoiedp9M+QLfkTxZKunRWDcs27Mh7Z5DP+5+vc/XkPP0txLe/yTuYSRW1JTOSLNEbxfN60tEk26eixMtdL+9k6awayvwFNAU6uevlndz0T19zvJZkprwyf0Gv1DzKZ92lfJ0rm8Ul+2rZkP4mr+CM+EiySL4jYnoSBppsn7BhsGD6WJZt2MEPH3yDZRt2sGD6WA61Bh0j0Aq9Lh695FSeXTiVlfNqmTi6zC5iaB03n51BPjukfJ0rk+KS0fRlR3x/k1dwRmYk3SDbNvhMj5esozEMg/rmDoKhMH6vm5Ch6QwZeD1uDMNIsg92FrbVtmTddh695NSEkXAoZLCvqYOlL7xnz2qWz5mA3+vm39bvAPLfGXSnpEqm9z0fJW4MQ6OUYu3iaTS0Blnxykds29uUdnHJu17eyfm1o6ko9lJV6qPcX5A12bKJlDkZGIgiSZNs28XTOV5XHZ5Th3ZOTRUHW4MsenwrlSU+bpg53l5T3HKIn1NTxUs7Dtj7VJf7CRvOCXQtHSH7dTAU5lBrB4FgmPbOMEtn1dgd3PVrt3P/xZPs2lJOnVcuneHpdkjZ+B5z3fklW43xsdf28JNvju+yuOS4yhJ+/I2vsujxrX3egd2X1lMReo4429Mk207Bro6XrqKJ3+apK07jot+8SV1jgJXzalm2YUfCOZ6+ciq7D7RQ5HXTFgzzlYoi/F43F6xILOmxdFYNix7fSnW5n98umsonDW0xium28ydwx8adACz73kksfsK588qHgzpaURV4XHhcioC55G1ZoYf61iCdYYOP6yM1zrbtbUq476mOGR8dlSulmOzZWLNoGlUlPhoDnSnPm86z2l/Lzwi9hzjbM8QwNIHOUFbt4l3Zv9NxtDqN5qKPazm+488RNnSMWeqh+ZMpL/awfM6EGCWxfM4Ebv/DTnsm8+mhgP25dawl67azdFYNXrfLViLR8q6/dgZhAwKdIb443E5liY+6xkBOHNSWjyoUMvj8cIADzR00tAbZ19hK7djhXBWl5CwFuG1vk20O/LwpQGfYoMDtoqok4uOKVn7n1FTxy+/UoBS4lMLvdTNyqD/rHXCyZ0Nrza76li6VcapnK9OioYLghCiSLrBG0l8cbs+qXTzeLDVxdBnXnT2OsNa2fyMdxRWfq1Df3GEftynQ6SjznoOtCR3+swuncvsfjkRtdYYNAO78wSkUuF24FLS0OyvTimIvFSXehM8qS3x83tQeM0uJ78CzsVhT9Mi63F/AzgPNMWadJy4/jbkPv+moABc9vpVzaqqobwnGyLlibi3V5YV2pz1xdBkLpo+1Z3uWoh0xpJAxFcVZ7YCT+WCUUmlFcSXb36WUo8nsjo07ZWVBISMkaqsLrJnBPZt2cdv5E7JW8iI6O3ni6DJumDmepS+8x+m3v8J5979K2NCO0SwFHlfKLODo46545SOWz4mVeeXcWgoLXDHRVnWNAVwuxXVnj7NDf+986UOuX7sdgGUb3ifQadAWDDvKVFbkxeNyJXx23dnjEmYpS9ZtZ/EZx9n7RgIAepbZ7Fjf7EAzd//xw5hzHmzpSBqqXF3u51+/U5Mg5+InttLacUSZLz7juIRghOvXbufThrYuiyUahuZQa+T6/n6olQPN7SmvMVnmuluR1uAi2WqOluJx+j5yEXUmGeuDB5mRdIE1M6hrDHDHxiMj9upyf0ZmjXiz1A8ffCPmB/6r3+1g5bzaBIdpS3uI+Y9sTmraiD+u3+vmuaum0xYM88WX7XjcKsHH8Zed+znUGkyIwhpW7GXFKx/x0o4D/PNZ4ziuqpj7L57E1U++bW935wWncP1v36Gy1Bsj7zk1VRxfVcKdF5xCU6DTdsrXNQY4rrKYtYunUVXqo6zQ02PfiWM15ce3snRWTUwwQUNr0HGEPsr0GwSCzjOtkKnMLaXjtE2R152yAzYMzScNrez/sj3mvqe6xvjvUCmFW0FY4xgoET8rdrkUI4b4WHXpFJragjS0Brlj405uPPeElAo1m1FnoZCRMDMU89nARRRJF0SbCbbtbbIdz89fPSPjH4RllvqssS3hB/7SjgMsm31SjP/D7YLv3vtqTMfpZJJwMnfNffhNls6q4ee/fSdhRPrMwqlcGKfIrl+7nVu/fzJrttZRXe6nvdPA1R7i3j/tYumsGiqKvVSW+li/7TO27W1i4ugyhhd7eWbhVBpbgxgafvTQG3Yn8sDFk2jpCPHoq3s42BLkwgffsIMD/r+39/LoJafidinChmbtlr9z+enHUVVamPL+RZv/rNUIy/wFVA3xMXF0me1MX7d1b4ICXDG3lqNKC/F4XHzeZDgqmgK3y47OSmYmbAuGCRmaUMjA40mc4De0Bvm0oc1W0qm+t/hno6LYm6BkV8yttZ+PVLPiQDBMQ0sHP3zwDbst1TWkM7tO10FvGJrPDwdsJZLuNQv9F1EkXZCPOPekNm2XK+ZH56Rw0jFJWB1uKue7U3uB28U5NVXceO6JuF2Kj+tbqW+OhBZbMq6+bAp7GwOcN2kU56943Xa8x3ecVz35Nstmn8Q/n/1VvO4jHb+h4aKpY3jqjU+YNKaCimIvF00dgwu6XJrWum+VJT5+/q3xMasRWoEC9S0dXP4Px/LE65+ybPZJHFtZjMel8LgUjYHOSKhyiY8Vc2sTfCRVJT6qSnw8dcVpNHeEEpSRlTtzy+928Mvv1FBdXpQgbzAUpsjr7tH31tAaTKg2cM+mD7n5uydx0z/plJ253+umosQX81xZps6YcPA0F1brTtRdQ2uQA83O5kTJWB+YiCLpgnzEuaerrFIlwqUaLVr7JRuRul3Ksf0rFUX8+OyvxpjS4p3lh1qDLPzH47jk0cg2K175iDt+cEpSM9BVT2zlmSunxnT859RUce1Z42I66ZVza3G5FMOKk49eK4q9rL5sCoaGprZgQl7L45dN4ZOGNnwFLnYdaGHXpl38++yvcVXUeazO8IQRpaxZNI1Q2MBjRm15TH+U5WCfOLqMJ684jc6wgVspvviynX9bv4Nte5tYePpx+L2ehNG21+O2fUvdDdQwzGoD0QrytvMn4FZQOcQfiUg7HIipl9bQGsQwDA62Brn7jx9y2/kT7P3rWzoYMaSQ566ebieopvssd6dcSzAUTmpOlIz1gYk429Mg16VP0i05nswJW+4vSLmolrXfuq17EwIG7r94Eo+/tiehfeW8SEe+qAtneUNrkAK3srfZtreJfU0BR6d8U6AzMgPSOsZxfX7taFuJWOdZ9MRWAsGuR68dIYNLHt3MnBWvs2zDDm7+7tf4QW01dY2R8N9LV73FtU9tY/EZx3Hd2eNsJWKd566Xd/LFl+3sb26nwO2iuryIo4YU0hjo5LPGNoKhMJUlRzrKYMigqa2TDw+0cPsfdtrZ5pYSt7AczcFQmBOOKuGuH5xi35Nzaqp46orTCIbCKZ3QYe1cbSCs4YN9XyZ83581tfFRfQuBToMir5tLZ4zlhW2fsXRWDWsXT2PNommMqSimqrSw289yd8q1eD1ux2dt5bzarM7kxZnfdxgQMxKl1EzgbsAN/EZrfWsvi9Rt0ik5nmx2dLC1w3G0+NzV06kqLbT3u+W8CRiGwZpF0wgbmt0HWlDAyv/5hM2fNMWYUIYVFdDRmbwwY3S29c3fPSlm9HnnSx8mmFCsmYw1A4o+blKTW1y/ED/r0uiE677mqbdZfdkUmgLBmLpfFcVehps5LBAxrf3snK8ysszPzi+aefHdfZx78kjGDi/G7VIs2/C+7Yd44OJJGFrT3mlw6aq3Yq7psdf2sGD6WB57bQ+TjplgyxlvBlp16amsWTgV5VIcag3GhBEnMxElW643EAwnKPgrV2/h8cun2D4wy/R20dRj7FnTq0vO7PEgqDtlYSqKvfzkm+Nts5xV6eDoLObcSPn5vkW/VyRKKTdwH/BNoA54Sym1Xmu9o3clyw1OCqe9MzJqjlYEK175iPZOI+l+nzW2cemqt1g5r5bqcr8dSACRDmLZ7JP4SkWRY+dRNSRyrsde28OPv/FVvG5lR2xVlvj4X98+kephfp5dOJVgWPPJwVbu2BjxV6yYW4u/wBVz3GQmtwIzgzw+M76yxMd1Z4/j2MriGHMWYJvbbjz3RH625h37WMcMK6K9M+zoU3Eyrd12/gTqm4Ns29vEVU++zapLp3DNU5ttE9fiM47D53Hxy1lf48nXI6VLyv0F1Dd3EOgMcTjQyfI5E3ApRVOgk9v/8DduOS+iaO7+44cJVZZvOW+Co1nMOR/EOQy4oSWYEDCxbPZJLD7jOJZt2JHQ6SdbTsDJRNodX2H0wCVX5uB8VnsWuqbfl0hRSk0DbtZaf8t8/wsArfV/OG2frfVI+lKJif2HA3x8sDUhK/3Y4cWMGOp33Mcqo+HkqLZmD5WlXv75rHGxPoV5kxkx1EcgGCZsaH71ux3UNwdZcu4JHD20EI9b8VljgJ+siYyMF/0/Y5g7bSyG1nhcimKfmxJvxBRnjarPqanin8/6Klc9ecTZff/Fk/B5XBT7PBS4FGENN69/j/rmIDeeewI/ixp5R/ttqssjZV2+OqKUD/c3s27r3kh9qhIvv3z+XRZMH0swZMQEAyQrJWMlLAL86Wf/yFl3/jcTR5fx82+N57HX9thFEStLfYws9fFRQ1tMR3vfRRNpbg9RWOBmWLGXIYWeyEywvjXhfh9fWUyBxxW5r1pH9vF7EzLZ77toEhXFBVz40JsJ8i6fM4Ev20Mxg4kbzz0Bt0tR7PN0WV7nofmT8XlcScPLo5/5+GKg5f6CLku3ZAvD0Ow7HAnJjw4tB3h1yZmMKi/KyXkHO6lKpAwERTIHmKm1vsJ8Pw84TWt9bdQ2C4GFAMccc0ztp59+mtE5+9q0el9TgAtWJtbJWrNoGlo7R/c4jfCPqShiX1OAO1/60A7pvX3OydQ1ttt1uUYP8zPMHIV+995ERfToJafGdNKWLKsunUJDS4d9jCGFHt7/vJkir5umQCebduzn3JNH8pWKSCdw64sf2KalaBOSz+PiX579q2Onv2zDDnvb82tHs2xDJBdnfFUp+5vbmXHbn5k4uozlF0zgG//5F3v/ZxdOjQmTjW+vLvfz5BWn8XF9K6OH+Wls7cTQOkaZrZxby92bPrRzPKwk0/gIqfJiLz9w+K6eWTiVfU1HFLCltMdVldgddMjQ3GIq7vhjr7r0VBpbgzH7L58zAY/LxahyP0cNKYz5/p3qcZ1TU8UNM0+koaXD7qDrWzoSRvlOz/+KubXcY15/Ln8PyQpaWjNemZHkjoFea8vpSY3RjlrrB4EHITIjyfSEfW1abSSxpX/eFGDOitfTSlxUSnHz+vdikt2uO3scl67aktDpLZt9ElWlPipLfCw+4zgee22PbaoZMaTQrqcVLUtrR8julJfPmUBbMIzX44rpjBdMH8PnTQFufO7dBAfz0lk1LFm3nScuP83xWsdVlbB0Vg1/2bmfG889kcOBTpbOquHuP37If5x/ckxJ9vhyN8lMa1WlPh695FRGlvmobz5SNj9eWVrBAbd+/2T7/i0+47iEumSLntjK01c6y98ZNmwlYLVd+fgRP1d9cwc/jOr4b//DTjuc2e91g4ZLHn0rwbT19JVTKSxwxUR3uVwqwXlulYCxou+iO+h4h7rT87/4iSOJoLn8PTide8m6iAnvqKGFUn6+l9iB+WgAAB7KSURBVBgIUVt1wOio99XA57k8YV9b1S3Z4kBW6Q7rhx1dyiPeNFdV4uMn3xwfE2VzTEWR43UWed0semIr1509jqOHFsYsiDX34Te5YeZ4Jo4ui5GlyOu2979+7XZKfR67UsCzC6eyfM4EyooKGD2siKWzamL2r2sMUFUaUU5WqHL8tfo8Lk4eNYRvTxjF/Ec2c979r7Fsww4u/4djae0Is/OLZsKGxut2MbzUGxNFtW7rXh6YW5sQzfbTNe/w9OZPKfYWxMyCkuWFHF3mt+VOFkDgUs7ye1wux+0tP1f8M7dtbxOXrnoLj0tRVVpIZzjJOjNa8917E6P54p8ZpxIwS9Zt57qzxyX4VlKtjhn93imKLdMIK+vcE0eXsXJeLc8unMrSWTWcMLJUHO29yECYkbwFjFNKjQU+Ay4ELsrlCfOxsFF3cHKERpd3h9gfdjLT3LjKEp67ejrtnQZus8Kt03VaYbxjhxcTMnRCSK3l5L101Vu2LO2d4RhZDI3t4LfMQFaZGCe/x1B/AefUVOF1K5bPmcCjrx7xUVSUeCkscBHoNLjmqVhZfvbbd1h92ZSY8i8PXDyJscOLee6q6XSGDcKG5sk3PrEjjKzSMAALpo9l/5ftMfcg2Qzm04Y2rjt7HPds2pWQDGht4/e6E76rlfNqUUo7bu9zK+qbOwhrzaOXnJpQ/t565go8Lsf9XUox/dgK1myti5kpxD8zFcWJRTet7zjdfCYrSi5etmyagr0eN+fUVCXk16ycV8uILiohCLmj389ItNYh4FpgI/ABsEZr/X4uz5ksn6O3ptXxeShrFk3jsdf22B2OJaP1w05mmmsMdDK82Ie/ILKdr8DlWPxvxSsf2bMMr1s5dkCjzagtK7rr88PtMbIUeI6MzJece4JjefrFZxxnn/PWFz/gl9+poaI40kFfe9Y4lm3YwZwVrzPv4c18uL+FxtagoyyHWmOjma568m2aAiFaOkKMHOqnuryIK04/npOOHkJ1uZ/PmwKcX1vN7XMi/hYruc5ixSsf8cDFkxLuyz2bdnF8VQm/+t5J3P6HDxzzKDpDBiOG+Hju6ulHcoaqSnErlVBg876LJnLQXOr49NtfYekL79mzvehnzjA0Le2hhP1vO38Cyza8z9xpX+EHtdX29QdD4YRn5ugyv+NMqcjnTiufacXcWtZt3Wu/j/49JHvemgLBbs9SKoq9/PI7NQmzp0WPb+2yeKaQOwbCjASt9e+B3+frfH1xVbfo8F7D0Pzkm+PZsa85ZgRo/bBTLdEbP3JcfdkUu+jjnqgw3ofmT6alI8SnDW2Oo9O9hwL2jOSBubX816YP7c/uvOAUGluDLJt9EsNLvJQUepL6PR6/bAo/XfMO2/Y28ctZNexvbsftciUkMF6/NrIssJMs8R1MXWOAprbIIldDizwYhrIjkfY1tds+GqszfmHbZwkZ4mVFBSybfZIdLGDdF3dUEmd9c9Ce5Rw1tJB//z/vJ3VGV5YU0hoM28dsC4YZVuyz65VFX+ezC6fGPHP1zR3Mf2QzlSURn87hQKddqHHb3iZ27Gvm0UtOteumKaX4rLEtYaEup/De4Q6VBZye/3J/AbecN4Gb/inx9+D0vFWW+NjX1G7fq3RnKS6XSshDsu6NlF/pPQaEIukN0kkg7C26UnTJTBNhTcLIcf4jm3n+6hlUl/nxelzcfeHX8bhd+AoUs+99jcoSX0wna428K0t8vLrkTAo8LtwKfvHtE/nFt2twKWIijw62BDnY4lxO49OGNoJhwzZvfXSglUtXvcUL18xw7EhaOkIJsljRRNFYymXZhh08feVUu7N2cqJbjn7Ln1NR7GWov4D/2rSb8yaNigkWiC/1Hp2bs3bxNNsR7+SM9nhcHDu8hKF+r+MiZdHXCcQ8e9EVqg+1BhMi0KJ9Syvm1tpBFfGdt/XMGIZBWEcSIhtag46DJKfnP9nvwel5u+7scY5Jlek46PuaaVkQRTJgSaXokiWXJcukNgwjIZ/Bip6qawzwwrbP7Oq9Po+LEWZVXacQ4zHDi7jx3BPxeVwUel20doT58dN/TVAAVjb5zet32JFez7/9GU9cPoVhxV7HjqS1I8SdL31oRzN9XN/Knz+IRHEtPP04GlqDrNu6lwXTx3LHxp3mKPaIkzqZE72i2Mu2vU0s27CDBy6exMGWDnaZJVKeWTgVIyrv40BLR9JZUXSF4qZAJ4ZhxJwr1SJl0ceK7zCjO9Zk/hufx8WaRdNiIvPiO+9kFYct/1lP80Scnrexw4tTziqslRzbO8O4zdUorcKS+SikKnQPUSSDkGQzlmSF9pxmKnsOtlJdHskSnz1xVEzpEKvjOdDSQWtHiFu/fzIlhR6ufWpbzDYjh5ZiGEEqS724FDx+2RTCWnOwJUhVqQ+PR3HvRRMBuPuPu5g9cRRL1m2nssSXUILlgYsnUVZUwJQxZQwr9tqznp9/a3xMgt19F03iyTc+tWc5+w4nd6Jbq1ZWlvr4nxvO5IvD7fzvF96nvqXDzld5//MvWbd1L7/8Tg11wQBfHG7n3osmxlzrirm1KEhIpFw5r5bK0sKkHXK6HWb0dk4VflfMjTii9ze3x4R3W99ltEkomT/jqStOS6usS7LnbVxlCWsWTbOXMvYkKRRqFSCNV2bxq1H2NdPyYKffJyR2l2xltg9EkkXXDCn0MOO2P8dsO3F0Gb/63kkciMqvsKgu9yd0PFZZ9+iIo+euns4wv5e/7W9OKOF+gtlJNbQGCXSGCIY0t//hg5iEvyXnnsCIIT4+Odhmrz2+cm4tvgIX3/jPv6TMWF+2YQf3XzyJe/+0i5d2HIipvfX3hjZefHcf500aFdMh33vRRFraQxS4XbQFwxxfVcx/bdptKzhbqc2tZUihh6a2Top9Hq7/7Ttcd/Y4x/uUKmnU+k7SXQPE2q7Q6yLYqel0qGQcn4RYXe6PMSd91tiW8F1DxDQ3Z8XrSffr7nO1+rIpdIQMx0iuBjPAIF7OZbNP4qRRQ/usSXmgM9ATEoUs0Z2ZSn1LByPLCin1OzvKo9ejsJzE0SVH6hoDtHWEgWDMMreVJZHkv4qSAg61dsassBdd/2rb3iYOBzpjFuoCWPTEVp5ZOJXqcn/SXA4refGJ1z/l8n84FiAxnNTMVI+WKxAMxzjiV8yt5bqzj48pV1LXGOCqJ7ay6tIplBR68JidfjKzWXTSqNPaIOn64tLZLp0ZTjL/g1PAQrrObadZzvxHNrP+2hmOs4pkvqGuVqMUeg9RJEIMTh1Ssg6ozO8lbJB2xxOdsFZd7ueLL9s5uqzQ3vcHtdUsPuM4DrUGaWkPJ6y9bjm+LWWULPchbGjuv3hS0nVACtwulm3YQWWJj8ICFzfMPNHO6LaOseiJ2CV7nTLVFz+xlccvm+JYMLOpLWgriNvOn0Bn2HkVxuik0UVPbLUztJOZjTKp8ZaOScjpu145r5a7/5gYsJCuczs6iTDaR9QZMhxrwSVTZpFqCOJQT5d81gMURSJ0SaoOqDsdT5u5vohl6ioscOExkx4rS3xcPPUrCYtoWTMQOOL4to5RWeqc9PdxfSv3bNrFry/8eoK/YPmcCRR5XTx1xWmEtWbew5u58wLnhbiiR+rJZjcaEupeLZ8TURzWNkvWbWf5nAkJslj+mujjFXndSaOXspHY19XMJVlob6pw8q5IlUTo5CNyeqYsH4k41NMj3/UAxUciZEz8yKfcX5AQ5bVybi1twTCG1jEFAZ+7arpd/8rJhxA9A4n3KZQVevi0sY29hwIxRSWv/+12tu1t4tmFU1m3tY4rTz/WXg/+ob98zI+/MY6RQ/3UNbVx+u2vJPWlPHnFaVxs+nmSFaN87LIpLHhkc0L7rd8/mbkPb7bb1i6eRmmhm8ICD/XNHTERZC9s+4yza0bYocU3rN3OvRdNTKhim46PI1dkMro1DE1dY5vtM7NIJfuRqK1IlYXoqC2ha3LxrIiPRMgpTqPc+IKQoPnOf/3/Cft2hg3Gjyil2Jc89BaOZEtHV7E1DE1nWMeUP4mMciP7GFpz3qTYiLLlcyZQ4I4UdPAXeCK+jlc+Sgg/vv/iSTz1xifc+v2TGTk0kuFtrbkSPWNq6wg5yn10WUQWS2GWFXkp9rn5275mu+5YfXOQx17bwzVnjrNLu1gy+r2JJpzerPGWSd5UT5IIXWYNMaFn5PtZEUUi5IRkORFWxeAyfwFtwUg2ucul7E49fgR11NBCXl1ypuMo2MmJu+jxrTx95VR27IsUaYyvJHz92u3cccEpNLQGGVdZYptQ7tgYqaY7ZngxhtbcZpaxX/k/n9iyRDuHrbVYzq8d7Sj3rgMtLNuwg/sumsiwYh8aTTBk8PTmT2PK47sUCfXBrl+7neeung7EzgRUktpnfc1v4DR7kSTC/JLv+y2KROgWPTVxVBR7WX3ZFPZ/2R7jJ7Cc9hXF3oQR/30XRdaTv+L04x1Hw8lGXWFDs/7aGTS3O88WFJG8mPXXzqCixMtTV55mJ70BfFzf6phvEQiGbXOTYWh+dd7JdIYM7r94UsLqinds3ElliY+2YJhrnootRmn5fZas287jl0+JkdFySAeCYQ582U7YMPisqZ2G1iBvf9LAirm1MaHSfS0RL1VBUEtpW8mpY4cXo9H2KphC9sh30qYoEiFtMnHguVyKkkIP8x+JjXyKdiwPL/Zy6/dP5qihhbiV4osv29n8SRPzpztPx5ONuvYcbOWkUUPxe5NXqU1W62lcZQlVSZz40aM5l0sxvNhHUyDICJePZxdOJWRo/vZFs13jauW8WsdilJbfp64xEFNh2Vp90Uq6tBYba+8M2/6U//PXui5zT/KF06Ai1Vo940eUsv7aGT2qsSV0j3wnbfb76r9C/kjWSTS0BlOuN2F9FggemUFY60ncecEpBENhDENH6nK5FJc8+hZn3vnfXL92OzfMHO/oL4DIqGtl3DoiVhXeYCjsWBH3zgtOYcUrHyWt9dQY6OTooX57LXtrv5XzajEMw742S6l+995XOe0//sSH+1v4uL6VZRt22KtLfrWqhDsvOIWV82rtdUqiw6Cry/34C9x2JV1rTRBr1cmlL7zH2Xf+Nzc+F1ki+LHX9jBpTAVaa0aVF9llTXoD6/rPuz9+rRPndVGsisNhA8f7LpV7s49lXs7HsyIzEiFtUjnwks1UAPuzpbNqbD9J/Drx1rQ7fgQf7S+Ix+VSjCwrdKzCq5SyK+JaOR5W1Fh9S0fKWk8ej48TjxqS4A+JLnQ4YogvRqkWed3c+uLfYpYFnvdI4mqD9eYyttZxhpf4GF7i4/mrZ9AWjJjirNUgnWYylr+ht0k2qFizaFrK2VxfWxROyA4yIxHSJtlKjEqppDOV6A7Hio667uxxCR3llau30J6kk+kMGUlnPGX+SIn2n/32HRY9vjVSJmVeLaBZOqsGgEWPb+WHD77BpaveYlRZJASyyOd8LVaHZ43mvB43F/3mzYRCh/Gzq2HFXupbOrhj405+OetrSVcbXDmvlq9XD7VNPS6Xss9V5PWkzMivKPZSVerrdZ+IYWgCnc7+J611yrV6kj1DfUE5Cj1HZiRC2iRz4EWXTreIHmVan23b28QdG3ey/IIJjtu7k0Ql+b3ulL6ZaFtw/OwhfqVFv9dDZakv6fob8Z10Uoe+xp5d3fTdGhpagzx22RT+3tCGwrmK8nGVxVSXF3VZpDF+TXnrPlSW+jh6qD+nJoqugiksk1YyGb0eN+NH+JPa5qVy78BEFImQNt2tGmyNMqM/27a3ib2HAkkVhlMnEzJ0UjOKlVdSUezliy/bueg3byTMBKwijdEdVrrOyGQO/UJz9ciW9hCBYDgmEm3l3FrOqamKifyqLvfjcbu6XLRp/IhSRgzxsXJubYxDeuW8WkYN9ePx5M6IkE4whTXDdFqHxrq/qXJOpHLvwEQy24WMSdUBAd2q/AokjIj3HQ44VqTd9NN/xO1SFHndtHSEONQa5JbffRBTz2nFKx9x94Vfx+/19KjD6uraPj8c4MIH30hQNNFZ8dXlRyoaRyuCVKP/fNZJsuhudeDo2lnV5X5G5ni2JPQuktku5JSuRplOnwFJt48fzSabFfz9UJu9nK9Vu8up7lVJoYdhDkvGZuPajCSLgbmUYs2iaYTiSrlbdDX6z/UKnE6KKh1HePR3Ya0AaSmbfCmR3lCyQmrE2S5khVShhk6fdSc00bKrn1NTxcp5taxdPI3Vl03hxXf3AUeiu4b6naO+QkZms24nWQ1Dc6C53c4Diaa63I+vwMVRQwrxez1orWkMdMaERKcKpbZIFVKdCclCdws8ri4d4dZ3kcyZnmuShx0PLstKX0NmJEKfx1ph78dnfzXGb3Db+RPYdaCFbXubYjrkaKyor2wSv4RwfFXfh+ZPZpjfeclaa8bR1eg/l9Vbkymx9dfO6NIR3ts+jlQJj7LgVe8hikToFzQGOhMS2aKzxKvL/RjaeW2UbIeWRndmdY0Bbv9DpE7XMcOK8HvdHDWksMsOr6taSLnsMJMpsUAwnJaSyLXZLRWSh9I3EdOW0C9I1oFYjt5Icl9BQqZ7Lswu8bJs29vEpave4mBLB1rrtGYcXZmIetJhpmsKS5XLkc9s6J4geSh9E5mRCP2CZCN4y9FrjZyHFHpzbnaxfAnxskSv4NfVjKMrE1F3q7d2xxTWn3M5+rPsAxkJ/xX6BZn6DLIZ6XOotYOPDrTwkzXvxESHVZb6OHZ4CS6XIhQy+Nv+5phKvU4hwNm63u4uZNSfI5/6s+z9GQn/Ffo9mTh5nTrl1ZdNoaTQQ2fI6HZnFAiG+X9//7eESsWlPo99jMZAJ/ds+jBmLfd7Nn3ILedNSMu/0N3r7a4prDf9HJnSn2UfqIgiEfoNPe1A4h3XlSU+9n/Zbpe07+7sxutxU9/SEbOUrjX6twiGwry040DCuiY3/VP6TuHuXK8sHCX0JuJsFwY88aP1xWccl5Bv0p1S5unkUvi9bh695FSeXTjVLiOfy469t/M7hMGNzEiEHtNfbNXxo/Vk1XXTDSHtMtvd0Oz/siNmLfnlcyYwYkhhzjr23s7vEAY3okiEHpHLhLlsEx/p0xYMZ2wGsgpFWoq0oTVod9zRhQ2j10IZWuTJ6b0ZjL6D/jKYGeiIIhF6RH/KMI4frSerMtyd2UIqRRoMhe3y8o2tnfY+ja2dlPv7Xm5Gf6U/DWYGOhL+K/SI6Cqw0by65ExGlRf1gkTdI9ORbKpwW4BPDrYSMoyEApLjjyrtcQFJIZbuhjz3FJn1RJDwXyHr9PcooUzNQKnCbUcO9dPRGebCh2LXRrl+7XaeXTgVinu/c+rt82eDfJRLkVlPekjUltAjBnuUUFdlRowkqySGdfoVbPNd/be/VdDNR7mUdKo0C6JIhB4S7Xd4dcmZMWuQDwa6UqSFBc6dXGGBK+0S8rnq7AdK55iPwYwUiUwPMW0JPWYwRglZdBVuO7zY5+jQH17sY9/hQJedU29U/+1vnWM+Qp77uwk3X2Q0I1FKXaCUel8pZSilJsd99gul1G6l1E6l1Lei2meabbuVUjdGtY9VSr2plNqllHpWKeU1233m+93m52O6Oocg5IOuFvNKNmNLxySTy85+IFXQzXW14sFuwk2XTE1b7wHfB/4S3aiUqgEuBL4GzATuV0q5lVJu4D7gXKAG+JG5LcBtwF1a63FAI3C52X450Ki1Ph64y9wu6TkyvB5ByBrJOrl0OqdcdvbSOabPYDfhpktGpi2t9QcASiXc1NnAM1rrDmCPUmo3MMX8bLfW+mNzv2eA2UqpD4CzgIvMbR4DbgYeMI91s9m+FrhXRU6Y7ByvZ3JNwuAmH9FM6ZhkclkuXbLgu8dgNuGmS658JKOAN6Le15ltAHvj2k8DKoAmrXXIYftR1j5a65BS6rC5fapzxKCUWggsBDjmmGN6dkXCgCefoZ5ddU657uzz2TkOhFBjITVdmraUUn9USr3n8Dc71W4ObboH7T05VmKj1g9qrSdrrSdXVlY6bSIIfS6aqa+vVpgOAyXUWEhNlzMSrfU3enDcOmB01Ptq4HPztVP7QaBMKeUxZyXR21vHqlNKeYChwKEuziEI3WagRDP1JfpTKR2h5+Qqj2Q9cKEZcTUWGAdsBt4CxpkRWl4izvL1OlKn5c/AHHP/BcALUcdaYL6eA/zJ3D7ZOQShRwykaKZ8kipxUpTz4CDT8N/zlFJ1wDTgd0qpjQBa6/eBNcAO4A/ANVrrsDnbuBbYCHwArDG3BVgC/NR0mlcAD5vtDwMVZvtPgRtTnSOT6xEGNxLN1H26Ml2Jch4cSNFGQYiiPzmG+4KsXRVOlFpVAwcp2igIadJfQj37SgfdlelKQo0HB1JrSxD6IX0lwiwd09VAiD7r7+SqAKiFKBJB6If01Imd7Q5F/Ep9n3yEYItpSxD6IT0pJpgLc5iYrvo++QjBlhmJIPRDejITyJU5TExXfZt8hGDLjEQQ+iE9mQlITsfgJB+l8GVGIgj9lO7OBCSnY3CSDz+W5JEIwiChr4QMC/knGzlHkkciCII4xgcxuc6PEkUiCIOI/pJwKfQvxEciCIIgZIQoEkEQBCEjRJEIgiAIGSGKRBAEQcgIUSSCIAhCRgy6PBKlVD3waR5POZzIUsJ9FZEvM0S+zOjL8vVl2SD/8n1Fa13p9MGgUyT5Rim1JVkST19A5MsMkS8z+rJ8fVk26FvyiWlLEARByAhRJIIgCEJGiCLJPQ/2tgBdIPJlhsiXGX1Zvr4sG/Qh+cRHIgiCIGSEzEgEQRCEjBBFIgiCIGSG1lr+0vgDPgHeBf4KbDHbhgEvA7vM/+VmuwLuAXYD24FJUcdZYG6/C1gQ1V5rHn+3ua9KQ6ZHgAPAe1FtOZcp2TnSkO1m4DPzHv4V+HbUZ78wz7MT+FZU+0yzbTdwY1T7WOBNU4ZnAa/Z7jPf7zY/H5Pk3o0G/gx8ALwP/LiP3b9k8vWJewgUApuBd0z5/q2nx8yW3GnItgrYE3Xvvt4b323UMdzANmBDX7l3Pe4fs3GQwfBHRJEMj2u73fqSgBuB28zX3wZeNB/QqcCbUQ/Zx+b/cvO11VFtBqaZ+7wInJuGTKcDk4jtrHMuU7JzpCHbzcDPHbatIfKj95kP+kfmj8xtvj4W8Jrb1Jj7rAEuNF+vAK4yX18NrDBfXwg8m+TejcTsMIBS4ENTjr5y/5LJ1yfuoXlNJebrAiKd09TuHjObcqch2ypgjsO15PW7jTrvT4GnOKJIev3e9bh/zMZBBsMfzopkJzDSfD0S2Gm+Xgn8KH474EfAyqj2lWbbSOBvUe0x23Uh1xhiO+ucy5TsHGnIdjPOneAvgF9Evd9o/kinARvjtzN/vAcBj9lub2fta772mNulM7t7AfhmX7p/SeTrc/cQKALeBk7r7jGzKXcasq3CWZH0xm+jGtgEnAVs6Mn3ket7150/8ZGkjwZeUkptVUotNNtGaK33AZj/q8z2UcDeqH3rzLZU7XUO7T0hHzIlO0c6XKuU2q6UekQpVd5D2SqAJq11yEE2ex/z88Pm9klRSo0BJhIZufa5+xcnH/SRe6iUciul/krEhPkykVFwd4+ZTbmTyqa1tu7dLea9u0spZa3w1Rvf7a+BGwDDfN+T7yMn964niCJJnxla60nAucA1SqnTU2zrtHap7kF7NukLMj0AHAd8HdgH3JkD2bolt1KqBFgH/IvW+stk22VZxrRxkK/P3EOtdVhr/XUio+spwIk9OGZO7mu8bEqpk4iMyk8ATiVirlqSZdnSQik1Czigtd4a3ZzimHm9dz1BFEmaaK0/N/8fAJ4n8sPZr5QaCWD+P2BuXkfEWWpRDXzeRXu1Q3tPyIdMyc6REq31fvMHbgAPEbmHPZHtIFCmlPLEtcccy/x8KHDISR6lVAGRTvpJrfVzXVxb3u+fk3x97R6aMjUBrxDxL3T3mNmUO5VsM7XW+3SEDuBRen7vMv1uZwDfVUp9AjxDxLz16xTX1Sv3rltkwz420P+AYqA06vVrRKIilhPrWLvdfP0dYp13m832YUSiRsrNvz3AMPOzt8xtLefdt9OUbQyxfoicy5TsHGnINjLq9U+AZ8zXXyPWafgxEYehx3w9liNOw6+Z+/yWWKfh1ebra4h1TK5JIpsCVgO/jmvvE/cvhXx94h4ClUCZ+doP/A8wq7vHzKbcacg2Mure/hq4tbd+G1GynsERZ3uv37se95HZOMhA/yMS/fAOR8IJ/9VsryDiMNtl/rceMgXcR8Rm/C4wOepYlxEJydsNXBrVPhl4z9znXtJzED9NxLzRSWQUcnk+ZEp2jjRke9w893ZgPbGd4r+a59lJVMQakYiaD83P/jXuO9lsyvxbwGe2F5rvd5ufH5vk3v0DkWn9dqJCafvQ/UsmX5+4h8AEIqGr281r/N89PWa25E5Dtj+Z9+494AmORHbl9buNk/UMjiiSXr93Pf2TEimCIAhCRoiPRBAEQcgIUSSCIAhCRogiEQRBEDJCFIkgCIKQEaJIBEEQhIwQRSIIgiBkhCgSQRAEISP+L5xeJ2tT6KSkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Look at homoscedasicity\n",
    "predictions = results.predict(X2_test)\n",
    "\n",
    "residuals = y2_test-predictions\n",
    "\n",
    "import seaborn as sns\n",
    "sns.scatterplot(predictions,residuals)\n",
    "residuals.sum()\n",
    "residuals.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model on the training set is: 0.6282197624998613\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: 0.6333142357506412\n",
      "Mean absolute error of the prediction is: 29158.33669410256\n",
      "Mean squared error of the prediction is: 1822300486.8325021\n",
      "Root mean squared error of the prediction is: 42688.411622271706\n",
      "Mean absolute percentage error of the prediction is: 18.038427410255746\n"
     ]
    }
   ],
   "source": [
    "# Retest the best performing linear model with the new 15 yr mortgage rates\n",
    "lrm2 = LinearRegression()\n",
    "lrm2.fit(X2_train, y2_train)\n",
    "y2_lrmpredict = lrm2.predict(X2_test)\n",
    "\n",
    "\n",
    "print(\"R-squared of the model on the training set is: {}\".format(lrm2.score(X2_train, y2_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the test set is: {}\".format(lrm2.score(X2_test, y2_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y2_test, y2_lrmpredict)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y2_test, y2_lrmpredict)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y2_test, y2_lrmpredict)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y2_test - y2_lrmpredict) / y2_test)) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I added the 15 yr mortgage rate that was available for buyers at the time the homes were sold. My idea was that better interest rates would create more demand for homes purchase and raise the price of homes. Although the linear regression with the 15yr rates feature mildly reduced percent error (18 vs 18.19), the r-squared value was decreased from 0.64 to 0.633. This is not surprising since the high p-value for mortgage rates suggests this feature is not playing a role in the predicting price with the other features in place. Mortgage rates might not provide solid predictive power as the rates were in flux and the economy was still recovering from the housing crisis between the years 2008-2011. Overall, the mortgage rate did not provide additional predictive power, at least with the feature combinations I was using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
